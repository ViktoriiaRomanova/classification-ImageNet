{"cells":[{"cell_type":"markdown","id":"0d869478","metadata":{"cellId":"m8ixcr7vzwml3qd9fuqcio","execution_id":"5d5d5a08-ddc8-422c-8379-9e3ef2193355","id":"0d869478"},"source":["# Train VGG model"]},{"cell_type":"code","execution_count":null,"id":"33ca9533","metadata":{"cellId":"hhn5plcggewkokx6b2tl","id":"33ca9533"},"outputs":[],"source":["#!g1.1 #noqa\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"d4bb1643","metadata":{"cellId":"ly5g0s5chi0nh26pvr55vh","id":"d4bb1643"},"outputs":[],"source":["#!g1.1 #noqa\n","!python3 --version"]},{"cell_type":"code","execution_count":null,"id":"5660da17","metadata":{"cellId":"bz620dfr2ylwon9y2tp3m","id":"5660da17"},"outputs":[],"source":["#!g1.1 #noqa\n","import sys\n","sys.path.append('/home/jupyter/work/resources/')"]},{"cell_type":"code","execution_count":null,"id":"6fe32814","metadata":{"cellId":"ma1a4v4jmoj9g41xra94e","id":"6fe32814"},"outputs":[],"source":["#!g1.1 #noqa\n","import pickle\n","import random\n","from typing import Any, Tuple\n","\n","import torch\n","import torch.nn as nn\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import f1_score\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchsummary import summary\n","from torchvision import transforms\n","from tqdm import tqdm\n","\n","from processingDataSet import conv_to_img, ImageNetDataset\n","from VGGModel import vgg19"]},{"cell_type":"code","execution_count":null,"id":"199be053","metadata":{"cellId":"rbdlgaxcadqby4uw75nw5","id":"199be053"},"outputs":[],"source":["#!g1.1 #noqa\n","data_path = '/home/jupyter/mnt/datasets/ImageNet/ILSVRC/Data/CLS-LOC/train'"]},{"cell_type":"code","execution_count":null,"id":"8a0cb368","metadata":{"cellId":"239fhyw32h12cr4ffpbvk8","id":"8a0cb368"},"outputs":[],"source":["#!g1.1 #noqa\n","random_seed = 10\n","device = 'cuda'"]},{"cell_type":"code","execution_count":null,"id":"d96338ae","metadata":{"cellId":"amd8lrxuiatxx7ovhefob","id":"d96338ae"},"outputs":[],"source":["#!g1.1 #noqa\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)"]},{"cell_type":"code","execution_count":null,"id":"de6234d3","metadata":{"cellId":"3b84bjz46ar70m33g4g2nv","id":"de6234d3"},"outputs":[],"source":["#!g1.1 #noqa\n","transform_train = transforms.Compose([\n","    transforms.Resize([224, 224]),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    transforms.RandomRotation(random.randint(0, 180)),\n","    transforms.RandomHorizontalFlip(p=0.2)])"]},{"cell_type":"code","execution_count":null,"id":"73533b8e","metadata":{"cellId":"ikxlawxy7tfwxqks8zp9k","id":"73533b8e"},"outputs":[],"source":["#!g1.1 #noqa\n","transform_test = transforms.Compose([\n","    transforms.Resize([224, 224]),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"]},{"cell_type":"code","execution_count":null,"id":"040151c8","metadata":{"cellId":"iaomb3vjk3co3skyp7fy7","id":"040151c8"},"outputs":[],"source":["#!g1.1 #noqa\n","model = vgg19(num_classes = 10).to(device)"]},{"cell_type":"code","execution_count":null,"id":"3e9ce84c","metadata":{"cellId":"ylt0jnbdlffw54tj01g2","id":"3e9ce84c"},"outputs":[],"source":["#!g1.1 #noqa\n","summary(model, (3, 224, 224), device = device)"]},{"cell_type":"code","execution_count":null,"id":"16993fcc","metadata":{"cellId":"ypkmt8yoksqjdc4be39xuc","id":"16993fcc"},"outputs":[],"source":["#!g1.1 #noqa\n","# Hyper parameters\n","lr = 0.01\n","batch_size = 64\n","epochs = 6"]},{"cell_type":"code","execution_count":null,"id":"3de3590e","metadata":{"cellId":"0ly4lk8qzk94l1hkqfv7lt","id":"3de3590e"},"outputs":[],"source":["#!g1.1 #noqa\n","with open('../filtered_data_10class.pkl', 'rb') as file:\n","    train_data = pickle.load(file)\n","    val_data = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"id":"a5077da9","metadata":{"cellId":"jotl93llbegirkcmpyttm","id":"a5077da9"},"outputs":[],"source":["#!g1.1 #noqa\n","train_set = ImageNetDataset(data_path, train_data, transform_train)\n","val_set = ImageNetDataset(data_path, val_data, transform_test)"]},{"cell_type":"code","execution_count":null,"id":"d8b41487","metadata":{"cellId":"0fekcb1tps5exl0mllvhsyi","id":"d8b41487"},"outputs":[],"source":["#!g1.1 #noqa\n","print('Train data size: ', len(train_set), 'Validation data size: ', len(val_set))"]},{"cell_type":"code","execution_count":null,"id":"8992300c","metadata":{"cellId":"r45d6gdeghsfie90gb7ahe","id":"8992300c"},"outputs":[],"source":["#!g1.1 #noqa\n","train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True, drop_last = True)\n","val_loader = DataLoader(val_set, batch_size = batch_size, shuffle = False, drop_last = True)"]},{"cell_type":"code","execution_count":null,"id":"f737c942","metadata":{"cellId":"6of7nq96srovkrvbsd0kdn","id":"f737c942"},"outputs":[],"source":["#!g1.1 #noqa\n","optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max',\n","                                                       factor = 0.1, patience = 3,\n","                                                       cooldown = 3)\n","loss_func = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"id":"90951f77","metadata":{"cellId":"1wtg3o047eeuaxewpe769d","id":"90951f77"},"outputs":[],"source":["#!g1.1 #noqa\n","def train(model: nn.Module, opt: torch.optim.Optimizer, scheduler: Any,\n","          loss_fn: nn.Module, epochs: int, data_tr: DataLoader,\n","          data_val: DataLoader, writer: SummaryWriter, start: int = 0) -> None:\n","    \"\"\"\n","    Start train and validation mode for epochs amount.\n","\n","    Save:\n","    * metrics into TensorBoard at each epoch;\n","    * model and optimizer parameters every 5 epochs.\n","    \"\"\"\n","    for epoch in range(start, start + epochs):\n","        avg_loss = 0\n","        train_accuracy = 0\n","\n","        model.train()\n","        for x_batch, y_batch in tqdm(data_tr):\n","            x_batch = x_batch.to(device)\n","            y_batch = y_batch.to(device)\n","\n","            opt.zero_grad()\n","            y_pred = model(x_batch)\n","            loss = loss_fn(y_pred, y_batch)\n","            loss.backward()\n","            opt.step()\n","\n","            # Calculate average train loss and accuracy\n","            avg_loss += (loss/len(data_tr)).detach().cpu()\n","            # !it is not final result, to get real accuracy need to divide into num_batches\n","            train_accuracy += torch.sum(torch.argmax(y_pred, 1) == y_batch) / len(y_batch)\n","\n","            del x_batch, y_batch, y_pred, loss\n","\n","        train_accuracy /= len(data_tr)\n","\n","        avg_val_loss = 0\n","        val_accuracy = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for x, y in data_val:\n","                x, y = x.to(device), y.to(device)\n","                y_pred = model(x)\n","                loss = loss_fn(y_pred, y)\n","                avg_val_loss += (loss/len(data_val)).detach().cpu()\n","                # !it is not final result to get real accuracy need to divide into num_batches\n","                val_accuracy += torch.sum(torch.argmax(y_pred, 1) == y) / len(y)\n","                del x, y, y_pred, loss\n","\n","            val_accuracy /= len(data_val)\n","\n","        writer.add_scalar('Lr', opt.state_dict()['param_groups'][0]['lr'], epoch)\n","        writer.add_scalars('Loss', {'train': avg_loss, 'val': avg_val_loss}, epoch)\n","        writer.add_scalars('Accuracy', {'train': train_accuracy, 'val': val_accuracy}, epoch)\n","        scheduler.step(val_accuracy)\n","\n","        print('Train_loss: ', avg_loss, 'Train_accuracy: ', train_accuracy, '\\n',\n","              'Val_loss: ', avg_val_loss, 'Val_accuracy: ', val_accuracy,\n","              'Lr: ', opt.state_dict()['param_groups'][0]['lr'])\n","\n","        if (epoch + 1) % 5 == 0:\n","            # Save model state\n","            torch.save({\n","              'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': opt.state_dict()},\n","                'checkpoints/modelOptE{0}.pt'.format(epoch))\n","\n","    writer.close()"]},{"cell_type":"code","execution_count":null,"id":"1a29b9ea","metadata":{"cellId":"8sieek5qt2cyaes8dbf6","id":"1a29b9ea"},"outputs":[],"source":["#!g1.1 #noqa\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"id":"2875e955","metadata":{"cellId":"zqrf2y5bygbglhk4a1cinf","id":"2875e955"},"outputs":[],"source":["#!g1.1 #noqa\n","start = 0\n","writer = SummaryWriter('runs/exp0', flush_secs = 1)\n","train(model, optimizer, scheduler, loss_func, epochs, train_loader, val_loader, writer, start = start)"]},{"cell_type":"code","execution_count":null,"id":"287cfcaf","metadata":{"cellId":"7cv1a0tqvrip3ahts55zss","id":"287cfcaf"},"outputs":[],"source":["#!g1.1 #noqa\n","# Save model state\n","torch.save({'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict()},\n","           'checkpoints/modelOptFinal.pt')"]},{"cell_type":"markdown","id":"ca63be81","metadata":{"cellId":"gzk1q2jaycqayzblczrxki","execution_id":"d1d3f377-f8ea-48a2-bc34-c7bdbe1b269b","id":"ca63be81"},"source":["# Look at the results"]},{"cell_type":"code","execution_count":null,"id":"71b63d9e","metadata":{"cellId":"nskqn5vkbxo3jopfvc7vr","id":"71b63d9e"},"outputs":[],"source":["#!g1.1 #noqa\n","def predict(model: nn.Module, loader: DataLoader) -> Tuple[torch.tensor, torch.tensor]:\n","    \"\"\"\n","        Predict class label.\n","\n","        Returns: Tuple[real, predicted]\n","    \"\"\"\n","    with torch.no_grad():\n","        logits = []\n","        real_label = []\n","\n","        for x, y in tqdm(loader):\n","            x = x.to(device)\n","            model.eval()\n","            y_pred = model(x).cpu()\n","            logits.append(y_pred)\n","            real_label.append(y)\n","            del x, y\n","\n","    pred = torch.argmax(torch.softmax(torch.cat(logits), dim=-1), 1)\n","    real = torch.cat(real_label)\n","    return real, pred"]},{"cell_type":"code","execution_count":null,"id":"a62d6595","metadata":{"cellId":"19y3h7l34wzhw8gwve5p5b","id":"a62d6595"},"outputs":[],"source":["#!g1.1 #noqa\n","f1_score(*predict(model, val_loader), average = 'macro')"]},{"cell_type":"code","execution_count":null,"id":"f4940a6e","metadata":{"cellId":"erte0smtbrrbywnp53qqek","execution_id":"8c876af0-56fd-45bd-826d-19da90ac888d","id":"f4940a6e"},"outputs":[],"source":["#!g1.1 #noqa\n","fig, ax = plt.subplots(4, 4, figsize = (20, 20))\n","ind = random.sample(range(len(val_set)), 16)  # get 16 random indexes of pictures\n","\n","with torch.no_grad():\n","    model.eval()\n","    for i, fig_x in zip(ind, ax.flatten()):\n","        x, y = val_set[i]\n","        x = torch.unsqueeze(x, 0).to(device)\n","        y_pred_prob = torch.softmax(model(x), dim = -1).cpu()\n","        prob = torch.max(y_pred_prob).item() * 100\n","        y_pred = torch.argmax(y_pred_prob)\n","        label = 'Real class: {0}, Predicted class: {1},\\n Probability: {2:.0f}%'.format(y, y_pred, prob)\n","        fig_x.title.set_text(label)\n","        fig_x.imshow(conv_to_img(x))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"78ba9c0f","metadata":{"cellId":"wxfw376drb8i2mngj2i3mo","id":"78ba9c0f"},"outputs":[],"source":["#!g1.1 #noqa"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"notebookId":"a72f27d5-e99f-424c-8142-729707cc4f77","notebookPath":"DataSphereWorkflow/trainVGGModel.ipynb"},"nbformat":4,"nbformat_minor":5}